<!-- This file needs to be edited by the lab developer to suit
the requirements of their lab in particular.-->

<!-- Add class="default" to include any element as it is
specified in default.html. 
Do not include class="default" to the elements that you want to
edit -->

<!DOCTYPE html>
<html>
<head>
</head>
<body>

<div id="experiment"> <!-- The Experiment Document Container-->

  <!-- The lab Header contains the logo and the name of the lab,
  usually displayed on the top of the page-->

  <header id="experiment-header" class="default">
  
    <div id="experiment-header-logo" class="logo">
      <img src="../images/logo-new.png" />
    </div>

    <div id="experiment-header-heading" class="heading">
      <!-- Write the name of your lab and link it to the home 
      page of your lab (h1 tag is preferred while writing your 
      lab name)-->
      <a href="../index.html">Speech Signal Processing Virtual Lab</a>	
    </div>

    <!-- Add any additional element you want to add to the lab 
    header, For example : Help (Enclosing them with suitable 
    div is recommended)-->

  </header>


  <!-- The lab article is the main content area where all the 
  experiment content sits-->
  <article id="experiment-article">
  
    <!-- The lab article has an header, optional navigational 
    menu, number of sections, an optional sidebar and a closing 
    footer-->
    
      <header id="experiment-article-heading" class="heading">
        <!-- You can add a welcome message or title of the 
        experiment here -->
        Expt-8: Linear Prediction Analysis of Speech
        <!-- Add any additional element if required with proper 
        enclosing-->
      </header>

      <!-- Navigation menu is useful to organize the view of 
      multiple sections inside the article-->
      <nav id="experiment-article-navigation" class="default">
        <ul id="experiment-article-navigation-menu">
          <!-- The menu can be dynamically generated to contain 
          the headings of your sections or instead write the 
          menu items of your choice individually enclosedu in 
          <li> tag as shown below-->
        </ul>
      </nav>

      <!-- All the sections of your lab or experiment can be 
      enclosed together with a div element as shown below-->
      <div id="experiment-article-sections">

        <!-- First section of the article-->
        <section id="experiment-article-section-1">
          
          <div id="experiment-article-section-1-icon" 
          class="icon">
	    <!-- Enclose the icon image of your lab -->
	    <img src="../images/introduction.jpg" />
	  </div>	
          
          <!-- The heading for the section can be enclosed in a 
          div tag. -->
          <div id="experiment-article-section-1-heading" 
          class="heading">
            Objective
          </div>

          <!-- Write the section content inside a paragraph 
          element, You can also include images with <img> tag -->
          <div id="experiment-article-section-1-content" 
          class="content">	
            <p>
	      <!-- PUT CONTENT HERE -->
	      The primary objective of this experiment is the study
	      of the characteristics of speech using linear prediction
	      analysis. This includes observing the LP spectrum and LP
		residual for voiced and unvoiced segments and 
	 	studying the effect of order of LP analysis (normalized error),
		autocorrelation of signal and LP residual for voiced and unvoiced
		segments, and study of glottal pulse shapes.
        </div>


      </section>

      <!-- Second section of the article-->
      <section id="experiment-article-section-2">
        
        <div id="experiment-article-section-2-icon" 
        class="icon">
	  <!-- Enclose the icon image of your lab. -->
	  <img src="../images/theory.jpg" />
	</div>
	<div id="experiment-article-section-2-heading" 
        class="heading">
          Tutorial
        </div>

        <div id="experiment-article-section-2-content" 
        class="content">
	    <!-- PUT CONTENT HERE -->
<p>
<h3>Source-system modeling of speech signals using LP analysis</h3>
</p>
<p>
The vocal tract system can be modeled as a time-varying all-pole filter using segmental analysis.
The segmental analysis corresponds to the processing of speech as short (10-30 ms) overlapped (5-15 ms) windows.
The vocal tract system is assumed to be stationary within the window and is modeled as an all-pole filter of order \( p \) using linear prediction (LP) analysis.
The LP analysis works on the principle that a sample value in a correlated, stationary sequence can be predicted as a linear weighted sum of the past few (\( p \)) samples.
If \( s(n) \) denotes a sequence of speech samples, then the predicted value at the time instant \( n \) is given by,
$$ \hat{s}(n) = \sum_{k=1}^{p}{a_k~s(n-k)} $$
where \( \{a_k\},~k=1,2,...,p \) is the set of linear predictor coefficients (LPC) and $p$ is the order of the LP filter. 
The error at time $n$ and the sum of squared errors \( E \) are given by,
$$ r(n)~=~s(n)~-~\hat{s}(n) $$
$$ E=~\sum_{n}{r^2(n)} $$
The cost function \( E \) is minimized with respect to \( \{a_i\},~i=1,2,...,p \) over the interval \( {-\infty}~{\leq}~n~{\leq}~{\infty} \) (autocorrelation formulation) as,
$$ {\partial{E}}/{\partial{a_i}}~=~0~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~1~{\leq}~i~{\leq}~p $$
This minimization leads to a set of normal equations,
$$ \sum_{k=1}^{p}{a_k~R(i-k)} = -R(i)~~~~~~~~~~~~~~1~{\leq}~i~{\leq}~p $$
where 
$$ R(i) = \sum_{n=-\infty}^{\infty}s(n)~s(n+i)~~~~~~~~~~-{\infty}~{\leq}~i~{\leq}~{\infty} $$
is the autocorrelation signal. The solution of these normal equations gives the values of the predictor coefficients \( \{a_k\},~k=1,2,...,p \).
The error signal \( r(n) \) obtained by inverse filtering the speech signal
is referred to as the LP <i>residual</i>.
The smooth variations (highly correlated) in the speech signal are captured by the LPCs and are attributed to the vocal tract characteristics.
The complex poles of the LP filter occur as conjugate pairs, and each pair represents a resonator cavity, with a maximum response at a frequency (called as <i>resonant frequency</i>) where the poles are located on the z-plane.
The vocal tract can be considered as a cascade of resonator cavities with different shapes and sizes.
The resonant frequencies of these cavities are referred to as <i>formants</i>.
The LP residual signal has large error values at regular intervals and can be attributed to the periodic impulses of excitation.
Hence the LP residual is a good approximation to the excitation source signal and can be used further to extract the excitation source characteristics.
A segment of voiced speech (windowed), frequency response of the inverse filter and the corresponding LP residual are shown in Fig.1.
</p>

<p>
<table border=0>
<tr><td width=800><img src=media/lpinvfilter.png /></td></tr>
<tr><td><b>Figure 1:</b> Inverse filtering the speech signal for estimating the excitation source (LP residual) signal.</td></tr>

</table><br>
</p>
<p><h1>Collection of voiced (/a/)and unvoiced (/s/) speech segments</h1></p>
<p>
<ul>
<li>Record a vowel /a/ for one second at 10 KHz sampling frequency
with 16 bit quantization. From this recorded speech file collect 200 ms
in steady portion of the waveform. </li>
<li>Record an unvoiced segment /s/ for one second at 10 KHz sampling
sampling frequency with 16 bit quantization. From this recorded speech
file collect 200 ms in steady portion of the waveform. </li>
<li>The short voiced and unvoiced speech segments are shown in
Figure&nbsp;1. </li>
</ul>
</p>
<p>
<a name="fig:voiced-unvoiced-waveform"></a><a name="183"></a> <img
src="media/img2.png"
alt="\resizebox*{15cm}{8cm}{\includegraphics{figures/figure1.eps}}"
style="border: 0px solid ; width: 681px; height: 363px;"><br>
<strong>Figure 1:</strong> <i class="sans">(a) Segment of voiced
speech /a/ and (b) segment of unvoiced speech /s/<br>
</i>
</p>
<p>
<h1>Short time spectrum, LP spectrum and Inverse spectrum for voiced
segment /a/</h1>
</p>
<p>
<br>
<h2>Short time spectrum</h2>
The short time spectrum consists of range of frequencies (magnitude and
phase components) that are present in a small segment (10-30 ms) of a
signal. Short time spectrum is computed with the following procedure:
</p>
<br>
<p>
<ul>
<li>Take 20 ms of voiced speech segment /a/ after preemphasis <br>
<span style="font-style: italic;">a=wavread('vowel.wav'); </span><br
style="font-style: italic;">
<span style="font-style: italic;">a=diff(a); </span><br
style="font-style: italic;">
<span style="font-style: italic;">a200=a(501:700);</span> </li>
<li>Apply a hamming window over a voiced segment (a200), then compute
the fast Fourier transform for the voiced segment (a200) and plot the
magnetite of the spectrum. <br>
<span style="font-style: italic;">ham=hamming(200); </span><br
style="font-style: italic;">
<span style="font-style: italic;">a200ham=a200.*ham; </span><br
style="font-style: italic;">
<span style="font-style: italic;">a200hamspec=fft(a200ham,1024); </span><br
style="font-style: italic;">
<span style="font-style: italic;">y=abs(a200hamspec.*a200hamspec); </span><br
style="font-style: italic;">
<span style="font-style: italic;">logy=10*log10(y); </span><br
style="font-style: italic;">
<span style="font-style: italic;">figure;plot([1:512]*5000/512,logy(1:512));grid;</span>
</li>
</ul>
</p>
<p>
<br>
<h2><LP spectrum=""></LP></h2>
<ul>
<li>LP spectrum provides smoothed envelope of the short time
spectrum, where only the formant frequencies (resonances) are observed.
For realizing this linear prediction coefficients (LPCs) or filter
parameters need to be computed from speech signal. <br>
<span style="font-style: italic;">ak=lpc(a200,14); </span><br
style="font-style: italic;">
<span style="font-style: italic;">lpspec=freqz(1,ak); </span><br
style="font-style: italic;">
<span style="font-style: italic;">y=abs(lpspec.*lpspec); </span><br
style="font-style: italic;">
<span style="font-style: italic;">logy=10*log10(y); </span><br
style="font-style: italic;">
<span style="font-style: italic;">figure;plot([1:512]*5000/512,logy);grid;
</span><br>
</li>
</ul>
</p>
<p>
<h2> Inverse spectrum </h2>
<ul>
<li>Inverse filter is realized by the inverse of LP filter. Therefore
the spectrum of the inverse filter is computed as follows: <br>
<span style="font-style: italic;">invspec=freqz(ak,1); </span><br
style="font-style: italic;">
<span style="font-style: italic;">y=abs(invspec.*invspec); </span><br
style="font-style: italic;">
<span style="font-style: italic;">logy=10*log10(y); </span><br
style="font-style: italic;">
<span style="font-style: italic;">figure;plot([1:512]*5000/512,logy);grid;
</span><br>
</li>
</ul>
</p>
<p>
The short time spectrum, LP spectrum and inverse spectrum for a segment
of voiced speech are shown in Figure&nbsp;2.
<a name="fig:voiced-spec"></a><a name="185"></a>
<br>
<img
src="media/img3.png"
alt="\resizebox*{15cm}{10cm}{\includegraphics{figures/fig2.eps}}"
style="border: 0px solid ; width: 680px; height: 454px;"><br>
<strong>Figure 2:</strong> <i class="sans">(a)
Segment of voiced speech /a/ and its (b) short
time spectrum, (c) LP spectrum and (d) inverse spectrum<br>
</i><br>
<br>
</p>
<h1>Short time spectrum, LP spectrum and Inverse spectrum for unvoiced segment /s/
</h1>
<ul>
<li>For computing the short time spectrum, LP spectrum and inverse
spectrum for an unvoiced segment /s/ the same procedure is followed as
that of for voiced speech segment /a/. </li>
<li>The short time spectrum, LP spectrum and inverse spectrum for a
segment of unvoiced speech (/s/) are shown in Figure&nbsp;3. </li>
</ul>
<img
src="media/img5.png"
alt="\resizebox*{15cm}{10cm}{\includegraphics{figures/fig3.eps}}"
style="border: 0px solid ; width: 680px; height: 454px;">
<br>
<a name="fig:unvoiced-spec"></a><a name="187"></a>
<strong>Figure 3:</strong>
<i class="sans">(a) Segment of unvoiced speech /s/ and its (b) short
time spectrum, (c) LP spectrum and (d) inverse spectrum.<br>
<br>
</i>
<h1>LP residual for voiced and unvoiced segments </h1>
<ul>
<li>LP residual signal is obtained by passing the speech signal
through inverse filter designed with LP coefficients (LPCs). The block
diagram of the inverse filter is shown in Figure&nbsp;4.<br>
<img
src="media/img6.png"
alt="\resizebox*{12cm}{3cm}{\includegraphics{figures/inversefilter.eps}}"
style="border: 0px solid ; width: 543px; height: 135px;"><br>
</li>
</ul>
<strong>Figure 4:</strong> <i class="sans">Inverse filter to obtain LP
residual signal from </i><strong></strong><i class="sans">
speech signal</i>
<ul>
<li>LP residual is computed for voiced and unvoiced speech segments
using the following matlab commands:&nbsp;</li>
<ul style="font-style: italic;">
<li>res=filter(ak,1,a200);&nbsp;</li>
<li>figure;plot(real(res));grid; <br>
</li>
</ul>
<li>Voiced and unvoiced speech segments and their LP residual signals
are shown in Figure&nbsp;5. </li>
</ul>
&nbsp;
<img
src="media/img7.png"
alt="\resizebox*{15cm}{10cm}{\includegraphics{figures/figure8.eps}}"
style="border: 0px solid ; width: 680px; height: 454px;"><br>
<a name="fig:residuals"></a><a name="191"></a><strong>Figure 5:</strong>
<i class="sans">(a) Segment of voiced speech /a/ and its (b) LP
residual signal, (c) segment of unvoiced speech /s/ and its (d) LP
residual signal.</i><br>
<br>
<br>
<h1>Autocorrelation function for
voiced/unvoiced speech segments and their LP residuals
</h1>
<br>
<ul>
<li>Autocorrelation function of the signal x(t) is computed using the
following formulation: <br>
<span class="MATH"><img
src="media/img8.png"
alt="$ R(\tau) = \sum_{t=0}^\infty{x(t)x(t+\tau)}$" align="middle"
style="border: 0px solid ; width: 209px; height: 39px;"><br>
</span> </li>
<li>The above formulation is implemented in matlab using the command
xcorr(x(t)). Autocorrelation function for voiced and unvoiced segments
and their LP residuals is computed. <br>
a200corr=xcorr(a200); </li>
<li>The autocorrelation function for the voiced speech segment and
its LP residual signal is shown in Figure&nbsp;6.</li>
<br>
<img
src="media/img9.png"
alt="\resizebox*{15cm}{10cm}{\includegraphics{figures/figure6.eps}}"
style="border: 0px solid ; width: 680px; height: 454px;"><br>
Figure 6:</strong><i class="sans">(a) Segment of voiced speech /a/ and
its (b)
autocorrelation function, (c) LP residual for the voiced speech segment
and its (d) autocorrelation function. </i><br>
<br>
<li>The autocorrelation function for the unvoiced speech segment and
its LP residual signal is shown in Figure&nbsp;7.<br>
<img
src="media/img10.png"
alt="\resizebox*{15cm}{10cm}{\includegraphics{figures/figure7.eps}}"
style="border: 0px solid ; width: 680px; height: 454px;"><br>
 </li>
<br>
<strong>Figure 7:</strong><i class="sans">(a) Segment of unvoiced
speech /s/ and its (b)
autocorrelation function, (c) LP residual for the unvoiced speech
segment and its (d) autocorrelation function.<br>
<br>
<br>
</i>
</ul>
<h1>Glottal pulse shape in voiced portion of a speech signal
</h1>
<ul>
<li>By integrating the LP residual we can obtain the glottal pulse
shape, it is also known as glottal volume velocity. </li>
<li>The integration function is implemented in matlab with a function
<i>cumsum</i>.&nbsp;<span style="font-style: italic;"></span></li>
<ul>
<li><span style="font-style: italic;">gp=cumsum(res);</span> </li>
</ul>
<li>A segment of voiced speech its LP residual and glottal pulse
(glottal volume velocity) waveforms are shown in Figure&nbsp;8. </li>
<img
src="media/img11.png"
alt="\resizebox*{15cm}{10cm}{\includegraphics{figures/figure5.eps}}"
style="border: 0px solid ; width: 670px; height: 457px;"><br>
<strong>Figure 8:</strong> <i class="sans">(a) Segment of voiced
speech /a/, its (b) LP residual and (c) glottal pulse waveform. </i>
</ul>
<ul>
<br>
<br>
<br>
</ul>
<h1>LP spectrum for different LP
orders
</h1>
<ul>
<li>Compute LPCs for different LP orders (14, 10, 6, 3 and 1), and
compute LP spectrum for each set of LPCs. </li>
<li>A segment of voiced speech and its LP spectrum for different LP
orders (14, 10, 6, 3 and 1) are shown in Figure&nbsp;9. </li>
<img
src="media/img14.png"
alt="\resizebox*{15cm}{20cm}{\includegraphics{figures/fig4.eps}}"
style="border: 0px solid ; width: 681px; height: 907px;"><br>
<strong>Figure 9:</strong> <i class="sans">(a) Segment of voiced
speech /a/, its LP spectrum for the LP order (b) 14, (c) 10, (d) 6, (e)
3 and (f) 1 </i> 
</ul>
<ul>
<br>
<h1>Normalized error for different LP orders for voiced/unvoiced speech
segments
</h1>
<ul>
<li>Normalized error is obtained by normalizing the LP residual
energy with respect to speech signal energy. </li>
<li>Normalized error is computed for both voiced and unvoiced
segments of speech with different LP orders. <br>
<!-- MATH
$\eta = \frac{residual energy}{signal energy}$
--><span
class="MATH"><img
src="media/img15.png"
alt="$\eta = \frac{residual energy}{signal energy}$" style="border: 0px solid ; width: 135px; height: 43px;"></span> <br>
for i=1:15 <br>
ak=lpc(a200,i); <br>
res=filter(ak,1,a200); <br>
<!-- MATH
$\eta(i)=\frac{sum(res.*res)}{sum(a200.*a200)}$
--><span
class="MATH"><img
src="media/img16.png"
alt="$\eta(i)=\frac{sum(res.*res)}{sum(a200.*a200)}$" style="border: 0px solid ; width: 167px; height: 47px;"></span>; <br>
end <br>
figure;plot(<span class="MATH"><img
src="media/img17.png"
alt="$\eta$" style="border: 0px solid ; width: 15px; height: 35px;"> </span>);grid;
</li>
<li>Normalized error for voiced and unvoiced segments of speech for
different LP orders is shown in Figure&nbsp;10</li>
</ul>
<img
src="media/img19.png"
alt="\resizebox*{15cm}{10cm}{\includegraphics{figures/figure4.eps}}"
&gt;="" style="border: 0px solid ; width: 681px; height: 454px;"><br>
<strong>Figure 10:</strong> <i class="sans">Normalized error for
voiced and unvoiced speech
segments for different LP orders. </i>
<br>
<br>
</ul>

        </div>				
				
       
      </section>


      <section id="experiment-article-section-3">
        
        <div id="experiment-article-section-3-icon" 
        class="icon">
	  <!-- Enclose the icon image of your lab. -->
	  <img src="../images/procedure.jpg" />
	</div>
      <!-- The heading for the section can be enclosed in a 
        div tag. -->
        <div id="experiment-article-section-3-heading" 
        class="heading">
          Procedure
        </div>

        <!-- Write the section content inside a paragraph 
        element, we can also include images with <img> tag -->
        <div id="experiment-article-section-3-content" 
        class="content">

	    <!-- PUT CONTENT HERE -->
	    <ol style="list-style-type: lower-alpha;">
	      <li>Take a segment (200 msec) of voiced speech /a/ and a segment (200 msec) of unvoiced speech /s/. </li>
	      <li>Compute short-time (20 msec) spectrum, inverse spectrum and 14<sup>th</sup>
		order LP spectrum for a voiced segment (/a/). </li>
	      <li>Compute short-time (20 msec) spectrum, inverse spectrum and 14<sup>th</sup>
		order LP spectrum for unvoiced segment (/s/). </li>
	      <li>Examine the LP residual for voiced and unvoiced segments. </li>
	      <li>Compute autocorrelation function of signal and its LP residual
		for voiced and unvoiced segments. </li>
	      <li>Obtain LP residual for the entire 200 msec of vowel and integrate
		to examine the glottal pulse shape </li>
	      <li>Obtain LP spectrum for a voiced segment for different orders of
		LP p=14,10,6,3,1 </li>
	      <li>Obtain normalized error for different orders for a voiced and
		unvoiced segment </li>
	      <li>Write a brief note on the observations </li>
	    </ol>

        </div>
        

      </section>


      <section id="experiment-article-section-4">

        <div id="experiment-article-section-4-icon" 
        class="icon">
	  <!-- Enclose the icon image of your lab.-->
	  <img src="../images/simulation.jpg" />
	</div>

        <div id="experiment-article-section-4-heading" 
        class="heading">
          Experiment
        </div>

        <div id="experiment-article-section-4-content" 
        class="content">
<p>
	    <!-- PUT CONTENT HERE -->

<applet code="audioTransport/SVLAudioTool.class" archive="media/lpSpectrumAnalysisS.jar" width="950" height="700" title="Java">
               <param name="foo" value="bar">
        Please install the latest version of the Java plugin for your browser. <br>
        </applet>
</p>
</div>

      </section>

      <section id="experiment-article-section-5">
   
        <div id="experiment-article-section-5-icon" 
        class="icon">
	  <!-- Enclose the icon image of your lab.-->
	  <img src="../images/manual.jpg" />
	</div>

        <div id="experiment-article-section-5-heading" 
        class="heading">
          Observations
        </div>

        <div id="experiment-article-section-5-content" 
        class="content">
	    <!-- PUT CONTENT HERE -->
<ul>
<li>Short time spectrum gives both source and system information. The
envelope of the spectrum gives system information (i.e., resonances in
terms of formant frequencies) and spectral ripples (fine variations)
give source information (i.e., pitch harmonics). It is a real and even
function of ω. </li>
<li>The linear prediction (LP) analysis models the vocal tract
system. LP spectrum observed to be an envelope of short time spectrum
(smoothed version of short time spectrum) and the peaks in LP spectrum
indicate the formant frequencies (resonances) of the vocal tract
system. With observation it is evident that the LP spectrum is derived
from an all-pole filter. </li>
<li>The inverse spectrum is observed to be reciprocal of the LP
spectrum. Therefore we can observe the valleys correspond to the peaks
in LP spectrum. It is represented by an all-zero filter.</li>
<li>For voiced speech segment its LP residual is observed to be
periodic. In LP residual signal, peak amplitudes refers to closure of
vocal folds (glottal closure), where the prediction is poor therefore
its results as maximum error. <br>
</li>
<li>The periodicity in LP residual also indicate the pitch
information.</li>
<li>LP residual is a result of passing the speech signal through
inverse filter (i.e., removing the vocal tract information). This is
also considered to be the excitation signal (source information).</li>
<li>LP residual for unvoiced speech segment looks like random noise.
As the unvoiced speech signal has no periodicity and looks like random
noise (no relations among the samples), obviously its input also looks
like noise.</li>
<li>The basic property of the autocorrelation function (even
symmetry) is evident in all (voiced/unvoiced speech and LP residual
signals) the plots. <br>
</li>
<li>The samples in a voiced speech segment are highly correlated,
therefore we will observe the peaks other than center are also
prominent. As voiced speech is periodic, it is inherited in its
autocorrelation function also. <br>
</li>
<li>In LP residual, the correlation among the samples is less,
therefore its autocorrelation function contains the peaks at pitch
rate. Hence autocorrelation function of a LP residual is useful for
pitch computation. <br>
</li>
<li>The autocorrelation function of an unvoiced speech segment shows
a major peak at the center and other peaks are not significant, since
unvoiced speech signal appears like random signal.&nbsp;</li>
<li>The autocorrelation function for the LP residual of an unvoiced
speech segment shows a dominant peak at the center and no other peaks
in rest of the portion. This is because, unvoiced speech itself looks
like random (no correlation among the samples) and its residual
reflects still random.This gives the information about the air pressure
build up near vocal folds from lungs, which cause the vibration of
vocal folds resulting in its open/closure. <br>
</li>
<li>Glottal pulse shape shows the change in volume of air. It is also
referred to as glottal volume velocity. <br>
</li>
<li>From the glottal pulse waveform, it is observed that volume of
air and its pressure will be maximum at the instant of closure.
Following this is the opening of the vocal folds, as a result of which
the air pressure decreases.</li>
<li>LP order determines to some extent the accuracy with which speech
production mechanism is modeled. <br>
</li>
<li>It uses an all-pole model to characterize the vocal tract system
by
capturing the resonances with spectrum and source information with LP
residual (inverse filter i.e., all zero filter). <br>
</li>
<li>LP order determines the number of resonances that can be captured
by
the model. The maximum number of resonances captured by the model with
LP order <span class="MATH">P</span> is P/2. <br>
</li>
<li>The length of the vocal tract from glottis to lips is
approximately 17
cm. This can generate four to five prominent resonances in 0-4 KHz
range. These resonances can be captured with the LP model of order 10.
We also should take care of radiation and windowing effects. Therefore
with LP order 10-14 we can model the system by capturing required
resonances.&nbsp; </li>
<li>System with LP order more than 14 will introduce the spurious
resonances, which leads improper representation of the vocal tract
system.</li>
<li>Normalized error for voiced speech signal reduces as the LP order
is varied from 0 to 15, since the vocal tract system (speech production
mechanism) is modeled more accurately as LP order varying from 0 to
15.&nbsp;</li>
<ul>
<li>P=0, no approximation, therefore maximum error&nbsp;</li>
<li>P=1, only one coefficient used for prediction, therefore error
is slightly less compared to that of P=0&nbsp;</li>
<li>P=10, model correctly approximates the resonances of the vocal
tract system, which leads to minimum error&nbsp;</li>
<li>P ≥ 10
also results the correct modeling of the vocal tract system, which
leads to similar error as that of model with P=10&nbsp;</li>
<li>For unvoiced speech signal, as the signal and residual energies
remains reasonable same, change in error as function of LP order is
relatively insensitive. Unvoiced speech signal itself appears like
random noise, therefore the prediction will remains poor even though if
we increase the LP order. Therefore both unvoiced speech signal and its
LP residual appears like noise, hence the normalized error for unvoiced
speech signal won't depend on the LP order.</li>
</ul>
</ul>
          </div>

        </section>

        <section id="experiment-article-section-6">
      
          <div id="experiment-article-section-6-icon" 
          class="icon">
	    <img src="../images/quizzes.jpg" />
	  </div>

          <div id="experiment-article-section-6-heading" 
          class="heading">
            Assessment 
          </div>

          <div id="experiment-article-section-6-content" 
          class="content">
<ol>
           			<li> What is the minimum no. of speech samples required to compute the LP coefficients of order p?
			<li> Explain the differences between autocorrelation and autcovariance formulations of LP analysis? Which is better and why?</li>
			<li> Suggest an algorithm for voiced/non-voiced region separation using:
				<ol>
					<li>a) LP residual energy</li>
					<li>b) peridicty information in the LP residual<li>
				</ol>
			</li>
			<li> Write an Octave/Scilab program that implements 3a and 3b</li>
			</ol>
         </div>

        </section>

        
			


 


		
        <section id="experiment-article-section-9">
   
          <div id="experiment-article-section-9-icon" 
          class="icon">
	    <!-- Enclose the icon image of your lab.-->
	    <img src="../images/readings.jpg" />
	  </div>

          <div id="experiment-article-section-9-heading" 
          class="heading">
            References
          </div>

          <div id="experiment-article-section-9-content" 
          class="content">
<ul>
			<li> <i>Digital Processing of Speech Signals</i>, L.R. Rabiner and L.R. Schafer, Chapter 8</li>
			<li> <i>Discrete-Time Speech Signal Processing</i>, Thomas F. Quatieri , Chapter 5</li>
</ul>     
     
          </div>

        </section>

      </div>


    <!-- An article can have a sidebar that contain related 
    links and additional material (however it is kept optional 
    at this moment) -->
    <aside id="lab-article-sidebar" class="default">
      <!-- put the content that you want to appear in the 
      sidebar -->	
    </aside>


    <!-- Article footer can display related content and 
    additional links -->						
    <footer id="lab-article-footer" class="default">
      <!-- Put the content that you want to appear here -->
    </footer>

  </article>


  <!-- Links to other labs, about us page can be kept the lab 
  footer-->
  <footer id="lab-footer" class="default">
    <!-- Put the content here-->
  </footer>



<footer id="lab-header" class="heading">
    <!-- Put the content here-->
    <div id="lab-header-heading" class="heading">
    <!-- Write the name of your lab and link it to the home page
    of your lab. -->
        <center>
        <table><tr>
                <td><a href="http://speech.iiit.ac.in/" target=_blank><font size=-3>Developed at the Speech and Vision Lab, IIIT Hyderabad</font></a></td>
        </tr></table>
        </center>
    </div>


  </footer>


</div>		
  <script type="text/javascript" src="../js/MathJax/MathJax.js?config=default">
  </script>

</body>
</html>
