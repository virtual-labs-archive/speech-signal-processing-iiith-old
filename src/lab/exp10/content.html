<!-- This file needs to be edited by the lab developer to suit
the requirements of their lab in particular.-->

<!-- Add class="default" to include any element as it is
specified in default.html. 
Do not include class="default" to the elements that you want to
edit -->

<!DOCTYPE html>
<html>
<head></head>
<body>

<div id="experiment"> <!-- The Experiment Document Container-->

  <!-- The lab Header contains the logo and the name of the lab,
  usually displayed on the top of the page-->

  <header id="experiment-header" class="default">
 <!-- 
    <div id="experiment-header-logo" class="logo">
      <!- Enclose the logo image of your lab or write it in 
      text ->
      <img src="../images/logo.jpg" /> 
    </div>
-->
    <div id="experiment-header-heading" class="heading">
      <!-- Write the name of your lab and link it to the home 
      page of your lab (h1 tag is preferred while writing your 
      lab name)-->
      <a href="../index.html">Speech Signal Processing Virtual Lab</a>	
    </div>

    <!-- Add any additional element you want to add to the lab 
    header, For example : Help (Enclosing them with suitable 
    div is recommended)-->

  </header>


  <!-- The lab article is the main content area where all the 
  experiment content sits-->
  <article id="experiment-article">
  
    <!-- The lab article has an header, optional navigational 
    menu, number of sections, an optional sidebar and a closing 
    footer-->
    
      <header id="experiment-article-heading" class="heading">
        <!-- You can add a welcome message or title of the 
        experiment here -->
        Expt-10: Analysis by synthesis
        <!-- Add any additional element if required with proper 
        enclosing-->
      </header>

      <!-- Navigation menu is useful to organize the view of 
      multiple sections inside the article-->
      <nav id="experiment-article-navigation" class="default">
        <ul id="experiment-article-navigation-menu">
          <!-- The menu can be dynamically generated to contain 
          the headings of your sections or instead write the 
          menu items of your choice individually enclosedu in 
          <li> tag as shown below-->
        </ul>
      </nav>

      <!-- All the sections of your lab or experiment can be 
      enclosed together with a div element as shown below-->
      <div id="experiment-article-sections">

        <!-- First section of the article-->
        <section id="experiment-article-section-1">
          
          <div id="experiment-article-section-1-icon" 
          class="icon">
	    <!-- Enclose the icon image of your lab -->
	    <img src="../images/introduction.jpg" />
	  </div>	
          
          <!-- The heading for the section can be enclosed in a 
          div tag. -->
          <div id="experiment-article-section-1-heading" 
          class="heading">
            Objective
          </div>

          <!-- Write the section content inside a paragraph 
          element, You can also include images with <img> tag -->
          <div id="experiment-article-section-1-content" 
          class="content">	
            <p>

	    <!-- PUT CONTENT HERE -->
The objective of this analysis-by-synthesis experiment is to break down the speech signal into different components such as the excitation source information (pitch and gain) and vocal tract system information (formants).
The various components derived by analysis of the speech signal is used to resynthesise the speech signal.
<!--The use of analysis-by-synthesis framework is illustrated for prosody (pitch and duration) modification. -->

        </div>


      </section>

      <!-- Second section of the article-->
     
      <section id="experiment-article-section-3">
        
        <div id="experiment-article-section-3-icon" 
        class="icon">
	  <!-- Enclose the icon image of your lab. -->

	  <img src="../images/theory.jpg" />
	</div>
     
        <div id="experiment-article-section-3-heading" 
        class="heading">
          Tutorial
        </div>

        <div id="experiment-article-section-3-content" 
        class="content">
	    <!-- PUT CONTENT HERE -->
	    

	<p>From a signal processing standpoint, it is very useful to think of speech
production in terms of a model, as in Figure 1.
The model shown is the simplest of its kind,
but it includes all the principal components.
The excitations for voiced and unvoiced speech are represented by an
impulse train and white noise generator, respectively.
The pitch of voiced speech is controlled by the spacing between
impulses, \(T_p\), and
the amplitude (volume) of the excitation is controlled by the gain factor \(G\).
As the acoustical excitation travels from its source (vocal cords,
or a constriction), the shape of the vocal tract alters the spectral
content of the signal.
The most prominent effect is the formation of resonances, which
intensifies the signal energy at certain frequencies (called formants).
As we learned in the Digital Filter Design lab, the amplification of certain
frequencies may be achieved with a linear filter by an appropriate
placement of poles in the transfer function.
This is why the filter in our speech model utilizes an all-pole LTI filter.
A more accurate model might include a few zeros in the transfer function,
but if the order of the filter is chosen appropriately, the all-pole model
is sufficient.
The primary reason for using the all-pole model is the distinct computational
advantage in calculating the filter coefficients, as will be discussed
shortly.Recall that the transfer function of an all-pole filter has the form
          $$V(z)=\frac{1}{1−\sum_{k=1}^{P} a_k z^−k} \qquad(1)$$,
where \(P\) is the order of the filter.

This is an IIR filter that may be implemented with a recursive difference equation.
With the input \(G x(n)\), the speech signal \(s(n)\) may be written as
			
          $$ s(n)=\sum\limits_{k=1}^{P} a_k s(n−k)+G x(n) \qquad (2)$$</p>
 <table width="600">
 <tr>
 	<td height="200">
 			<img src="images/lpmodel.png" alt="Speech production model"  style="height:100%;width:90%">
 	</td>
 </tr>
<caption align="bottom"><b>Figure 1. </b><em>Impulse+noise model of speech production</em> </caption> 
 </table> 
 <br>        
 <p> Keep in mind that the filter coefficients will change continuously as
the shape of the vocal tract changes, but speech segments of an
appropriately small length may be approximated by a time-invariant model.
This speech model is used in a variety of speech processing applications,
including methods of speech recognition, speech coding for transmission,
and speech synthesis.
Each of these applications of the model involves dividing the speech signal
into short segments, over which the filter coefficients are almost constant.
For example, in speech transmission the bit rate can be significantly
reduced by dividing the signal up into segments, computing and sending
the model parameters for each segment (filter coefficients, gain, etc.),
and re-synthesizing the signal at the receiving end, using a model
similar to Figure 1.
Most telephone systems use some form of this approach.
Another example is speech recognition.
Most recognition methods involve comparisons between short
segments of the speech signals, and the filter coefficients of this model
are often used in computing the “difference" between segments.</p>


<h3>Speech Coding and Synthesis</h3>
<p>One very effective application of LPC is the compression
of speech signals.
For example, an LPC vocoder (voice-coder) is a system used in
many telephone systems to reduce the bit rate for the transmission of speech.
This system has two overall components:
an analysis section which computes signal
parameters (gain, filter coefficients, etc.), and a synthesis section which
reconstructs the speech signal after transmission. Since we have introduced the speech model,
and the estimation of LPC coefficients,
we now have all the tools necessary to implement a simple vocoder.
First, in the analysis section,
the original speech signal will be split into short time frames.
For each frame, we will compute the signal energy, the LPC coefficients,
and determine whether the segment is voiced or unvoiced.	</p>    
<br>
<br>
<p>
<b>Adapted from: </b> Bouman, Charles A., "Lab 9b - Speech Processing (part 2)." Connexions. 
	    September 17, 2009. from http://cnx.org/content/m18087/1.3/ under the
	    Creative Commons Attribution 2.0 Generic License.

</p>	    

        </div>

      </section>
 <section id="experiment-article-section-2">
        
        <div id="experiment-article-section-2-icon" 
        class="icon">
	  <!-- Enclose the icon image of your lab. -->
	  <img src="../images/procedure.jpg" />
	</div>
				
        <!-- The heading for the section can be enclosed in a 
        div tag. -->
        <div id="experiment-article-section-2-heading" 
        class="heading">
          Procedure
        </div>

        <!-- Write the section content inside a paragraph 
        element, we can also include images with <img> tag -->
        <div id="experiment-article-section-2-content" 
        class="content">
	    <!-- PUT CONTENT HERE -->
	    <ul>
		<LI><p>Choose any of the pre-recorded speech signals and load them.  </P> </li>
		<li><P>Study the characteristics of generated LP residual signal. This residual is generated using a 
			LP order of 11 and will be used to synthesize the speech signal in futher stages of experiment. </P></li>
		<li><P>Choose from the dropdown menu, type of excitation signal that would be used to synthesize the 
			speech signal. Also choose the order of LP coefficients to be used to synthesize the speech. </P> </li>
		<li><p>Click on the 'Synthesize' button to synthesize speech signal according to the parameters chosen. 
		    Study the characteristics of the resynthesised speech by using different excitation types, namely, 
			LP residual, impulse excitation and random noise excitation.</p></li>
		<li><p>Study the effect of using the vocal tract system derived using different LP orders for resynthesis. Zoom into the waveform to study different regions of synthesized waveform.</p></li>
		<li><p>Repeat the experiment for sentences recorded with your own voice.</p></li>

	</ul>

        </div>
      </section>



      <section id="experiment-article-section-4">

        <div id="experiment-article-section-4-icon" 
        class="icon">
	  <!-- Enclose the icon image of your lab.-->
	  <img src="../images/simulation.jpg" />
	</div>

        <div id="experiment-article-section-4-heading" 
        class="heading">
          Experiment
        </div>

        <div id="experiment-article-section-4-content" 
        class="content">
	    <!-- PUT CONTENT HERE -->
	<p>
		<applet code=analysisSynthesis.AnalysisSynthesisApplet.class archive="media/analysisSynthesisS.jar" width="900" height="800" >
		</applet>
	</p>
        </div>

      </section>

      <section id="experiment-article-section-5">
   
        <div id="experiment-article-section-5-icon" 
        class="icon">
	  <!-- Enclose the icon image of your lab.-->
	  <img src="../images/manual.jpg" />
	</div>

        <div id="experiment-article-section-5-heading" 
        class="heading">
          Observations
        </div>

        <div id="experiment-article-section-5-content" 
        class="content">
	    <!-- PUT CONTENT HERE -->
<ul>
<li><P>The LP residual signal used as excitation, there are large error values at regular intervals within voiced regions of speech. These are the instants of glottal closure at which the vocal tract system is excited. Hence the LP residual signal can be approximated to the excitation source signal.</li><br></P>

<li><P>Resynthesis of the speech signal using the LP residual (excitation source) and the LPCs (vocal tract system) gives back the original speech signal. But the synthesized waveform doesn't exactly corresponds to original speech signal waveform. This is because of the different orders of LP analysis used to generate residual signal and synthesize speech signal.</li><br></P>

<li><P>The excitation source signal can be approximated by a train of impulses, but the quality of synthesized speech is poor though the message can be inferred easily.</li><br></P>

<li><P>The resynthesised speech signal sounds like a whispered speech when a random noise signal is used as the excitation source.</li><br></P>

<li><P>It can be seen that an LP order of as low as 3 can capture significant information on the message front even when an impulse train or random noise is used as the excitation. The quality of speech improves with the increase in the LP order. But using the original LP residual signal gives very good synthesis even for the 3rd order LP coefficients.</P></li><br>
</ul>
          </div>

        </section>
<!--
        <section id="experiment-article-section-6">
      
          <div id="experiment-article-section-6-icon" 
          class="icon">
	    <img src="../images/quizzes.jpg" />
	  </div>

          <div id="experiment-article-section-6-heading" 
          class="heading">
            Q & A
          </div>

          <div id="experiment-article-section-6-content" 
          class="content">
           
          </div>
        </section>
	-->

        <section id="experiment-article-section-7">
	  
          <div id="experiment-article-section-7-icon" 
          class="icon">
	    <!-- Enclose the icon image of your lab. -->
	    <img src="../images/quizzes.jpg" />
	  </div>
	
          <div id="experiment-article-section-7-heading" 
          class="heading">
	    Assessment
	  </div>
	
          <div id="experiment-article-section-7-content" 
          class="content">
            	    <!-- PUT CONTENT HERE -->
		    <ol>
	<li><P>Write a program (C/Matlab/Octave/Scilab) to separate the source and system of a given speech signal of 1 to 2 seconds using short-time LP analysis. Use a window size of 20 ms, a window shift of 10 ms, an LP order of 10. Plot the original signal and the LP residual signal.</li><br></P>

	<li><P>Write a program (C/Matlab/Octave/Scilab) to resynthesize the speech signal given the sequence of LPCs and the following excitation signals:
	<ul>
	<li>LP residual derived by using a specified LP order</li>
	<li>Train of unit impulses with a constant pitch of 10 ms.</li>
	<li>Train of impulses with the gain varying proportional to the LP residual signal</li>
	<li>White Gaussian random noise sequence with and without the gain of the LP residual signal imposed.</li>
	</ul></P>
	</li><br>

</ol>
	  </div>
	
        </section>
			
		
        <section id="experiment-article-section-8">
   
          <div id="experiment-article-section-8-icon" 
          class="icon">
	    <!-- Enclose the icon image of your lab.-->
	    <img src="../images/readings.jpg" />
	  </div>

          <div id="experiment-article-section-8-heading" 
          class="heading">
        References  
		</div>

          <div id="experiment-article-section-8-content" 
          class="content">
    <ul>
                        <li> <p><i>Digital Processing of Speech Signals</i>, L.R. Rabiner and L.R. Schafer, Chapter 8</p></li>
                        <li> <p><i>Discrete-Time Speech Signal Processing</i>, Thomas F. Quatieri , Chapter 5</p></li>
</ul>
 
          </div>

        </section>

      </div>


    <!-- An article can have a sidebar that contain related 
    links and additional material (however it is kept optional 
    at this moment) -->
    <aside id="lab-article-sidebar" class="default">
      <!-- put the content that you want to appear in the 
      sidebar -->	
    </aside>


    <!-- Article footer can display related content and 
    additional links -->						
    <footer id="lab-article-footer" class="default">
      <!-- Put the content that you want to appear here -->
    </footer>

  </article>


  <!-- Links to other labs, about us page can be kept the lab 
  footer-->
  <footer id="lab-footer" class="default">
    <!-- Put the content here-->
  </footer>

<footer id="lab-header" class="heading">
    <!-- Put the content here-->
    <div id="lab-header-heading" class="heading">
    <!-- Write the name of your lab and link it to the home page
    of your lab. -->
        <center>
        <table><tr>
                <td><a href="http://speech.iiit.ac.in/" target=_blank><font size=-3>Developed at the Speech and Vision Lab, IIIT Hyderabad</font></a></td>
        </tr></table>
        </center>
    </div>


  </footer>


</div>		
<script type=text/javascript src=../js/MathJax/MathJax.js?config=default></script>

</body>
</html>
